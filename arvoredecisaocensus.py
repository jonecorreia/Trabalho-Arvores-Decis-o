# -*- coding: utf-8 -*-
"""arvoreDecisaoCensus.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rVDyrGiWYnxu_VIO1zO3V4b0LCgN37Av
"""

#ls /content/drive/MyDrive/ColabFiles/

!pip -q install plotly --upgrade
!pip -q install yellowbrick

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px

from google.colab import drive
#drive.mount('/content/drive')

from google.colab import drive
drive.mount('/content/drive/')

base_census = pd.read_csv('/content/drive/MyDrive/ColabFiles/census.csv')
#base_census

#opc
base_census

#Divisão entre previsores e classe
#exibir nome das colunas, opc
base_census.columns

#separar os dados x para previsores e y para classes. iloc transforma em array numpy
X_census = base_census.iloc[:, 0:14].values
X_census

#y para classes. iloc cria array
y_census = base_census.iloc[:, 14].values
y_census
#base_census

#Tratamento de atributos categóricos [dividido em 2 etapas: labelEncoder e OneHotEncoder]
#1 parte: LabelEncoder [ tranforma strings em indices numericos]
from sklearn.preprocessing import LabelEncoder

#exibe linha de registro do bd com diversos tipos de dados, numericos e strings.
X_census

#criar um objeto p cada coluna q vai ser alterada [cjto de indices 1: masculino, 2: feminino]
label_encoder_workclass = LabelEncoder()
label_encoder_education = LabelEncoder()
label_encoder_marital = LabelEncoder()
label_encoder_occupation = LabelEncoder()
label_encoder_relationship = LabelEncoder()
label_encoder_race = LabelEncoder()
label_encoder_sex = LabelEncoder()
label_encoder_country = LabelEncoder()

from pandas.core.internals import base
#substitue nas colunas, conforme a posição no bd
#função fit.transform p mudar de string p mnumero
X_census[:,1] = label_encoder_workclass.fit_transform(X_census[:,1])
X_census[:,3] = label_encoder_education.fit_transform(X_census[:,3])
X_census[:,5] = label_encoder_marital.fit_transform(X_census[:,5])
X_census[:,6] = label_encoder_occupation.fit_transform(X_census[:,6])
X_census[:,7] = label_encoder_relationship.fit_transform(X_census[:,7])
X_census[:,8] = label_encoder_race.fit_transform(X_census[:,8])
X_census[:,9] = label_encoder_sex.fit_transform(X_census[:,9])
X_census[:,13] = label_encoder_country.fit_transform(X_census[:,13])
X_census[0]
#base_census

# temmos um array só com numericos
X_census

#parte 2: 
#OneHotEncoder: cria novas colunas com base nos indices
##tecnica p calcular pesos das colunas por codificacao dos elementos, [array 1,2,3: o 3 tem mais peso q o 1]. 

from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer

onehotencoder_census = ColumnTransformer(transformers=[('OneHot', OneHotEncoder(), [1,3,5,6,7,8,9,13])], remainder='passthrough')

#X_censusOriginal = X_census
X_census = onehotencoder_census.fit_transform(X_census.toarray())

X_census

X_census[0]

X_census.shape

#Escalonamento dos valores
#deixar valores na mesma escala. p evitar o peso nas colunas[3+ importante 1]
#Standardization [padronização] ou normalização[normalization]
#Padronização é mais indicada qdo temos outliers[registros fora do padrão]

from sklearn.preprocessing import StandardScaler
scaler_census = StandardScaler()
X_census = scaler_census.fit_transform(X_census)

X_census[0]

#Divisão das bases em treinamento e teste
from sklearn.model_selection import train_test_split

#cria as variaveis p treinamento e teste. 
#x atributos previsores, y p classes. test-size 15% p testar,85% p treinar 
X_census_treinamento, X_census_teste, y_census_treinamento, y_census_teste = train_test_split(X_census, y_census, test_size = 0.15, random_state = 0)

#x atributos previsores, y p classes.
#exibe linhasxcol, #85% dados treinamento [sem oneHotEncode: 14 colunas, com OHE:116 col]
X_census_treinamento.shape, y_census_treinamento.shape

#15% dados p teste,lin x col, [sem OHE: 14, com OHE: 116]
X_census_teste.shape, y_census_teste.shape

#Salvar as variáveis
import pickle

#crio arquivo .pkl 
with open('census.pkl', mode = 'wb') as f:
  pickle.dump([X_census_treinamento, y_census_treinamento, X_census_teste, y_census_teste], f)

#--arvore de decisão--#
#carregar a bib sklearn
from sklearn.tree import DecisionTreeClassifier

#import pickle

with open('census.pkl', 'rb') as f:
  X_census_treinamento, y_census_treinamento, X_census_teste, y_census_teste = pickle.load(f)

X_census_treinamento

y_census_treinamento

#fit define a arvore dec. atrib previsores, classe e realiza o treinamento
arvore_census = DecisionTreeClassifier(criterion='entropy',max_depth=3, random_state = 42)
arvore_census.fit(X_census_treinamento, y_census_treinamento)

#testes
#Naïve Bayes
from sklearn.naive_bayes import GaussianNB

with open('census.pkl', 'rb') as f:
  X_census_treinamento, y_census_treinamento, X_census_teste, y_census_teste = pickle.load(f)

X_census_treinamento.shape, y_census_treinamento.shape

X_census_teste.shape, y_census_teste.shape

#previsão do alg
naive_census = GaussianNB()
naive_census.fit(X_census_treinamento, y_census_treinamento)
previsoes = naive_census.predict(X_census_teste)
previsoes

#compara com bd orginal
y_census_teste

#acuracia
#gerar a metricas p calcular a acuracia ou tx de acerto
from sklearn.metrics import accuracy_score, classification_report

#calcula acuracia
accuracy_score(y_census_teste, previsoes) # não executar o escalonamento

#gerar  a matriz de confusão do naive bayes
from yellowbrick.classifier import ConfusionMatrix

cm = ConfusionMatrix(naive_census)
cm.fit(X_census_treinamento, y_census_treinamento)
cm.score(X_census_teste, y_census_teste)

print(classification_report(y_census_teste, previsoes))

#=========#
#retorna a importancia de caada atributo depois dos calculos do maior ganho de inform
arvore_census.feature_importances_

#exibe as classes da arvore
arvore_census.classes_

#desenha a arvore
from sklearn import tree
figura, eixos = plt.subplots(nrows=1, ncols=1, figsize=(20,20))
tree.plot_tree(arvore_census, class_names=arvore_census.classes_, filled=True);

